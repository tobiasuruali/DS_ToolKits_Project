{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3\n",
    "Firstly the same main.py code was more or less copy pasted.\n",
    "To enable quick parameter and architecture changes, the train_model() function was taken out of the module and is utilized to give a greater overview of parameter choices. For Task 3 we disabled the DB part but if you want to run test with docker-compose, it will be enabled over there.\n",
    "\n",
    "## Data\n",
    "We chose the same Mnist Dataset as and as you can see by the first out put, the train set consists of 60'000 img's with a (28,28,1) shape. 1 cause it we normalized it and made it greyscale.\n",
    "We build the model with the set parameters and wait for it to run through all the epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-08 22:28:07.383830: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-08 22:28:07.383920: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Dec  8 22:28:21 2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtobiasuruali\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "2021-12-08 22:28:30.461933: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-08 22:28:30.462023: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/unilu-dstoolkits/ipynb_test_runs/runs/21gld4tv\" target=\"_blank\">helpful-bee-16</a></strong> to <a href=\"https://wandb.ai/unilu-dstoolkits/ipynb_test_runs\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-08 22:28:36.831722: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-12-08 22:28:36.832958: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-12-08 22:28:36.833017: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (tobias-VirtualBox): /proc/driver/nvidia/version does not exist\n",
      "2021-12-08 22:28:36.833659: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                16010     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-08 22:28:37.257198: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 169344000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-08 22:28:39.578868: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 11075584 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/422 [..............................] - ETA: 12:22 - loss: 2.3003 - accuracy: 0.1406"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-08 22:28:39.788296: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 17981568 exceeds 10% of free system memory.\n",
      "2021-12-08 22:28:39.789364: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 17981568 exceeds 10% of free system memory.\n",
      "2021-12-08 22:28:39.844454: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 11075584 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422/422 [==============================] - 54s 125ms/step - loss: 0.3593 - accuracy: 0.8921 - val_loss: 0.0852 - val_accuracy: 0.9777\n",
      "Epoch 2/12\n",
      "422/422 [==============================] - 51s 121ms/step - loss: 0.1153 - accuracy: 0.9650 - val_loss: 0.0585 - val_accuracy: 0.9847\n",
      "Epoch 3/12\n",
      "422/422 [==============================] - 181s 430ms/step - loss: 0.0853 - accuracy: 0.9738 - val_loss: 0.0464 - val_accuracy: 0.9885\n",
      "Epoch 4/12\n",
      "422/422 [==============================] - 52s 124ms/step - loss: 0.0726 - accuracy: 0.9772 - val_loss: 0.0419 - val_accuracy: 0.9898\n",
      "Epoch 5/12\n",
      "422/422 [==============================] - 46s 108ms/step - loss: 0.0646 - accuracy: 0.9798 - val_loss: 0.0416 - val_accuracy: 0.9892\n",
      "Epoch 6/12\n",
      "422/422 [==============================] - 51s 121ms/step - loss: 0.0578 - accuracy: 0.9815 - val_loss: 0.0346 - val_accuracy: 0.9912\n",
      "Epoch 7/12\n",
      "422/422 [==============================] - 46s 109ms/step - loss: 0.0522 - accuracy: 0.9835 - val_loss: 0.0381 - val_accuracy: 0.9902\n",
      "Epoch 8/12\n",
      "422/422 [==============================] - 45s 108ms/step - loss: 0.0489 - accuracy: 0.9843 - val_loss: 0.0321 - val_accuracy: 0.9907\n",
      "Epoch 9/12\n",
      "422/422 [==============================] - 43s 101ms/step - loss: 0.0465 - accuracy: 0.9851 - val_loss: 0.0311 - val_accuracy: 0.9925\n",
      "Epoch 10/12\n",
      "422/422 [==============================] - 56s 134ms/step - loss: 0.0442 - accuracy: 0.9860 - val_loss: 0.0315 - val_accuracy: 0.9908\n",
      "Epoch 11/12\n",
      "422/422 [==============================] - 57s 136ms/step - loss: 0.0403 - accuracy: 0.9867 - val_loss: 0.0324 - val_accuracy: 0.9905\n",
      "Epoch 12/12\n",
      "422/422 [==============================] - 54s 128ms/step - loss: 0.0374 - accuracy: 0.9882 - val_loss: 0.0280 - val_accuracy: 0.9925\n",
      "Saving Model: <keras.engine.sequential.Sequential object at 0x7fe718714040>\n",
      "Loading Model from volumes..\n",
      "Current directory:\n",
      "/home/tobias/Desktop/DS_ToolKits_Project\n",
      "Test loss: 0.02561642974615097\n",
      "Test accuracy: 0.991100013256073\n"
     ]
    }
   ],
   "source": [
    "import codepy.data_preparation as data_preparation\n",
    "import codepy.build_model as build\n",
    "import codepy.model_inspection as inspection\n",
    "import codepy.predictions as predictions\n",
    "import numpy as np\n",
    "import random\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "# import database_pg\n",
    "import time\n",
    "\n",
    "print(time.ctime())\n",
    "\n",
    "\n",
    "def initialize_wandb():\n",
    "    wandb.init(project=\"ipynb_test_runs\", entity=\"unilu-dstoolkits\")\n",
    "initialize_wandb()\n",
    "num_classes, input_shape, x_train, y_train, x_test, y_test = data_preparation.prepare_data()\n",
    "#Comment form here..\n",
    "model = build.build_model(num_classes, input_shape)\n",
    "def train_model(x_train, y_train, x_test, y_test, model):\n",
    "    wandb.config = {\n",
    "        \"epochs\": 12,\n",
    "        \"batch_size\": 128,\n",
    "        \"loss\": \"categorical_crossentropy\",\n",
    "        \"optimizer\": \"adam\",\n",
    "        \"metrics\" : \"accuracy\",\n",
    "        \"validation_split\" : 0.1,\n",
    "        \n",
    "    }\n",
    "\n",
    "    model.compile(loss= wandb.config['loss'], optimizer= wandb.config['optimizer'], metrics= [wandb.config['metrics']])\n",
    "\n",
    "    model.fit(x_train, y_train, batch_size= wandb.config['batch_size'],\n",
    "              epochs= wandb.config['epochs'], validation_split= wandb.config['validation_split'],\n",
    "              validation_data=(x_test, y_test),\n",
    "              callbacks=[WandbCallback()])\n",
    "\n",
    "# Call function\n",
    "train_model(x_train, y_train, x_test, y_test, model)\n",
    "inspection.save_model(model)\n",
    "#..To here for testing purposes \n",
    "loaded_model = inspection.load_model()\n",
    "inspection.evaluate_loaded_model(x_test, y_test, loaded_model)\n",
    "# predictions.predict_on_data(x_test, y_test, loaded_model)\n",
    "# database_pg.create_milestone3_db()\n",
    "# database_pg.create_input_pred_db()\n",
    "# random_img_x, squeezed_random_img_x, img_from_db = database_pg.insert_load_random_image()\n",
    "# database_pg.predict_and_persist(img_from_db, loaded_model)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions\n",
    "\n",
    "We load our saved model as in previous milestones, and let it predict x_test dataset. We then with the help of argmax turn the model from a nparray categorical into an array with single int's. Same goes for the y_train dataset.  \n",
    "This is done to enable easier comparison of the predictions (for corr matrix, and image filter) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Dec  8 22:52:20 2021\n",
      "Predictions array: [7 2 1 ... 4 5 6] (10000,) (10000, 10) <class 'numpy.ndarray'> (10000, 28, 28, 1)\n",
      "Y Test array: [7 2 1 ... 4 5 6] (10000, 10) <class 'numpy.ndarray'> (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(time.ctime())\n",
    "\n",
    "# Predicting something with loaded_model\n",
    "prediction  = loaded_model.predict(x_test)\n",
    "# print(prediction)\n",
    "\n",
    "#convert to int array \n",
    "int_predictions = np.argmax(prediction, axis = 1)\n",
    "print('Predictions array:', int_predictions, int_predictions.shape, prediction.shape, type(x_test), x_test.shape)\n",
    "\n",
    "int_y_test = np.argmax(y_test, axis = 1)\n",
    "print('Y Test array:', int_y_test, y_test.shape, type(x_test), x_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction visualization\n",
    "Firstly we create a quick visualization on wandb of random numbers with their respective predictions. With the help of wandb.log function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Dec  8 22:52:31 2021\n",
      "Random Numbers selected in array: [4188, 366, 6142, 4323, 744]\n",
      "Showcase to evaluate predictions:\n",
      "4188\n",
      "366\n",
      "6142\n",
      "4323\n",
      "744\n"
     ]
    }
   ],
   "source": [
    "print(time.ctime())\n",
    "\n",
    "random_numbers = random.sample(range(0,10000),5)\n",
    "print('Random Numbers selected in array:', random_numbers)\n",
    "\n",
    "print('Showcase to evaluate predictions:')\n",
    "for i, number in enumerate(random_numbers):\n",
    "    wandb.log({\"img\": [wandb.Image(x_test[random_numbers[i]], \n",
    "                                   caption=int_predictions[random_numbers[i]])]})\n",
    "    print(random_numbers[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix \n",
    "With the help of wandb.log's conf_mat function, we can plot the y_test (ground truth) data and our predictions. We used 0-9 to name the different classes.\n",
    "Confusion matrix's are used to visualize the accuracy of the predictions an on what occasions (numbers in our case) the predictions struggled the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Dec  8 22:52:37 2021\n",
      "(10000, 10) (10000, 10)\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "print(time.ctime())\n",
    "\n",
    "#Create Confusion Matrix \n",
    "print(y_test.shape, prediction.shape)\n",
    "#Create class names 0-9\n",
    "class_names = (list(range(0,10)))\n",
    "print(class_names)\n",
    "\n",
    "wandb.log({\"conf_mat\" : wandb.plot.confusion_matrix(probs=None,\n",
    "                        y_true=int_y_test, preds=int_predictions,\n",
    "                        class_names=class_names)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Prediction/Truth Table (Histogram)\n",
    "To create a great overview of how/where our model wrongly predicted images. A table was created with the colums:  \n",
    "- **id** : index inside the x_test array  \n",
    "- **image** : original 28x28 greyscale image from x_test  \n",
    "- **prediction** : predicted number (int) of the image made by our model   \n",
    "- **truth** :  ground truth (int) of the image  \n",
    "\n",
    "We filled the table with all 10'000 x_test images and respective prediction/truth values. With filtering on wandb you can then visualize all wrong predictions a model produced.\n",
    "We created a  **WANDB report** to visualize the wrong predictions on specific numbers and what wrong predictions were made the most (histogram):\n",
    "https://wandb.ai/unilu-dstoolkits/ipynb_test_runs/reports/Visualization-Task-3--VmlldzoxMzE0MTY3\n",
    "\n",
    "**NOTE: To not fill up our wandb directory we decided to run this part only once, in future uses the table only gets filled with random images. Similarly to the earlier code snippet** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Dec  8 22:52:45 2021\n",
      "4188\n",
      "366\n",
      "6142\n",
      "4323\n",
      "744\n"
     ]
    }
   ],
   "source": [
    "print(time.ctime())\n",
    "\n",
    "#Create table to visualize the predictions \n",
    "\n",
    "columns=[\"id\", \"image\", \"prediction\", \"truth\"]\n",
    "img_ids = (list(range(5,10)))\n",
    "prediction_table = wandb.Table(columns=columns)\n",
    "\n",
    "#To save a table of all predictions/images \n",
    "# for i, pictures in enumerate(int_predictions):\n",
    "#     prediction_table.add_data(i, wandb.Image(x_test[i]), int_predictions[i], int_y_test[i])\n",
    "\n",
    "for i, number in enumerate(random_numbers):    \n",
    "    prediction_table.add_data(random_numbers[i], wandb.Image(x_test[random_numbers[i]]), int_predictions[random_numbers[i]], int_y_test[random_numbers[i]])\n",
    "    print(random_numbers[i])\n",
    "wandb.log({\"prediction_table\": prediction_table})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finish and Save\n",
    "Finish the wandb init run and save all the data to wandb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Dec  8 22:52:50 2021\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 36239... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a69f17ad79b849a28928a71a8cad111e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.47MB of 0.47MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▆▇▇▇███████</td></tr><tr><td>epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>loss</td><td>█▃▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▆▇▆▇▇▇█▇▇█</td></tr><tr><td>val_loss</td><td>█▅▃▃▃▂▂▂▁▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.98817</td></tr><tr><td>best_epoch</td><td>11</td></tr><tr><td>best_val_loss</td><td>0.02804</td></tr><tr><td>epoch</td><td>11</td></tr><tr><td>loss</td><td>0.03735</td></tr><tr><td>val_accuracy</td><td>0.9925</td></tr><tr><td>val_loss</td><td>0.02804</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 8 media file(s), 7 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">helpful-bee-16</strong>: <a href=\"https://wandb.ai/unilu-dstoolkits/ipynb_test_runs/runs/21gld4tv\" target=\"_blank\">https://wandb.ai/unilu-dstoolkits/ipynb_test_runs/runs/21gld4tv</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211208_222823-21gld4tv/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(time.ctime())\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "91001342a52700311bfaf3b01c2e025c2fc002160a7f3b4d189119299144eceb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('virtualenvPY': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
